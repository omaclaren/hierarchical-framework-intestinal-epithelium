{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sampling simulations\n",
    "OJM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg as la\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import scipy.interpolate as interpolate\n",
    "import scipy.special as special\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import os\n",
    "import errno\n",
    "import george\n",
    "from george import kernels\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO - add into modules?\n",
    "%run data_analysis_functions.ipynb\n",
    "%run simulation_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_sim(data_dir='../data-working/TXT_BrdU/',sample_type='BrdU',\n",
    "                          actual_out_times= np.array([60.,120.,360.,600.,1080.,1920.]),times_to_fit_i=[5],precision_time=4,\n",
    "                          p0=np.array([1.0,2.0,0.01,0.01,0.01]),p_var_i=[],x_min=0.,x_max=100.,\n",
    "                          k=3,s=15,nx=100,n_walkers=10,n_dim=4,n_burn=10,n_sample=10):\n",
    "    \"\"\"\n",
    "    sampling solution to inverse problem\n",
    "    -\n",
    "    notes\n",
    "    a key difficulty is choosing proper comparison grid\n",
    "    also, systematic regularisation - dependence on number of parameters etc? determining reg. parameter\n",
    "    best passing of parameters etc\n",
    "    -\n",
    "    structure\n",
    "    initial condition\n",
    "    data for fitting\n",
    "    model definition\n",
    "    residuals function\n",
    "    likelihood\n",
    "    prior\n",
    "    posterior\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #---\n",
    "    #get initial condition\n",
    "    files_in_dir= os.listdir(data_dir)\n",
    "    files_in_dir.sort() #assumes files have same name format!!\n",
    "\n",
    "    start= actual_out_times[0]\n",
    "    time_format= '%0'+('%1d' % precision_time)+'d'\n",
    "    file_ic= get_data_file(data_dir,time_format%start)\n",
    "    \n",
    "    density_results= process_and_fit_label_data_file(data_dir=data_dir,file_to_fit=file_ic,\n",
    "                                                     sample_type=sample_type,x_max=x_max,\n",
    "                                                     do_plot=False)\n",
    "    initial_profile_f= density_results[-1]\n",
    "    \n",
    "    #---\n",
    "    #data for comparison. NOTE - ignore initial profile [todo - change?]\n",
    "    #TODO - use times_to_fit_i???\n",
    "    #x_data_to_fit= np.tile(np.arange(x_min,x_max),(actual_out_times.size-1,1))\n",
    "    x_data_to_fit= np.tile(np.arange(x_min,x_max),(len(times_to_fit_i),1))\n",
    "    x_data_to_fit= np.transpose(x_data_to_fit)\n",
    "    #print 'x data'\n",
    "    #print x_data_to_fit\n",
    "    label_data_at_x_data= np.zeros(x_data_to_fit.shape)\n",
    "    sample_size_at_x_data= np.zeros(x_data_to_fit.shape)\n",
    "\n",
    "    for i in range(0,len(times_to_fit_i)):\n",
    "        current_time= actual_out_times[times_to_fit_i[i]]\n",
    "        file_current= get_data_file(data_dir,time_format%current_time)\n",
    "        print file_current\n",
    "        data_result= process_and_fit_label_data_file(data_dir=data_dir,file_to_fit=file_current,sample_type=sample_type,k=k,s=s,x_max=100,do_plot=False)\n",
    "        sample_size_result= get_sample_sizes_for_data_file(data_dir=data_dir,file_to_fit=file_current,sample_type=sample_type,k=k,s=s,x_max=100,do_plot=False)\n",
    "        #careful here - data grid concept needs to be tidied up.\n",
    "        label_data_at_x_data[:,i]= np.append(data_result[0],np.zeros(x_max-data_result[0].size))\n",
    "        sample_size_at_x_data[:,i]= np.append(sample_size_result,np.zeros(x_max-sample_size_result.size))\n",
    "    \n",
    "    #convert between experimental times and simulation times \n",
    "    norm_out_times= (actual_out_times-min(actual_out_times))/(max(actual_out_times)-min(actual_out_times))\n",
    "    \n",
    "    #---\n",
    "    #function for one sim.\n",
    "    def model(p_var_model):\n",
    "        \"\"\"\n",
    "        simulation model\n",
    "        -\n",
    "        notes:\n",
    "        output formats for each quantity are -\n",
    "        [column of results at time 1|column of results at time 2|...etc...]\n",
    "        uses arguments from outer function - bad practice?\n",
    "        bit of a hack with 'global' vs. local arguments.\n",
    "        inputs - only the 'substantive' part - not the 'noise parameters'\n",
    "        TODO - split 'noise' and 'substantive' out. First, fix noise.\n",
    "        \"\"\"\n",
    "        p= np.copy(p0) #careful of python 'labels/tags' vs 'containers'.\n",
    "        p[p_var_i]= np.copy(p_var_model[p_var_i]) #WHAT TO DO HERE? careful of python 'labels/tags' vs 'containers'.\n",
    "        #print 'test p0 changing:' \n",
    "        #print p==p0\n",
    "        #print p[p_fixed_i]== p0[p_fixed_i]\n",
    "        #print 'here'\n",
    "        velocity_f= velocity_from_integrated_proliferation(proliferation_profile(p=p,x_max=x_max))\n",
    "        controller= setup(nx=nx,initial_profile_f=initial_profile_f,velocity_f=velocity_f,norm_out_times=norm_out_times)\n",
    "        #controller.verbosity= 0\n",
    "        controller.run()\n",
    "\n",
    "        #extract (all) simulation results\n",
    "        output_shape= [np.size(controller.frames[0].state.q[0,:],axis=0),np.size(controller.frames,axis=0)]\n",
    "        #print output_shape\n",
    "        labels= np.zeros(output_shape)\n",
    "        x_centres= np.zeros(output_shape)\n",
    "        velocity= np.zeros(output_shape)\n",
    "        for i in range(0,np.size(controller.out_times,axis=0)):\n",
    "            labels[:,i]= controller.frames[i].state.q[0,:]\n",
    "            #don't actually vary with time!\n",
    "            x_centres[:,i]= controller.frames[0].state.grid.c_centers[0]\n",
    "            velocity[:,i]= controller.frames[0].state.aux[0,:]\n",
    "\n",
    "        return labels, velocity, x_centres\n",
    "\n",
    "    #---\n",
    "    #residuals function\n",
    "    def residuals(p_var_current,flatten_residual=True,return_model=False):#,p0=np.array([1.0,2.0,0.01,0.01,0.01]))#,p_fixed_i=[]):#,x_data_to_fit=x_data_to_fit,label_data_to_fit=label_data_to_fit,times_to_fit=[]):\n",
    "        \"\"\"\n",
    "        residuals between model solutions and data\n",
    "        -\n",
    "        notes\n",
    "        data and model results are matrices/arrays!\n",
    "        in 'column vector' storage format? Each column vector is a space grid; column index is a time?\n",
    "        added 'return_model' option (default off for compat.) so can return model values as well (for any extra calc.).\n",
    "        -\n",
    "        Plan\n",
    "        general outline\n",
    "        -at a given time\n",
    "        [vectorised]\n",
    "        --at a set of data comparison x points\n",
    "        ---get data values\n",
    "        ---get solution values (via interp.)\n",
    "        ---compute residual and store as column vector in residual matrix\n",
    "        -(in another function) square values and sum to get a single scalar\n",
    "        approach\n",
    "        -test cell to consider a vector of data values and test sim and calc residual\n",
    "        \"\"\"\n",
    "        #get solutions at all fit times\n",
    "        results= model(p_var_model=p_var_current)\n",
    "        labels_model= results[0][:,times_to_fit_i] #note: changed indexing\n",
    "        x_centres_model= results[2][:,times_to_fit_i] #note: changed indexing\n",
    "        \n",
    "        #print 'labels_model'\n",
    "        #print labels_model\n",
    "\n",
    "        #data grid. TODO - do better. Note: don't include initial condition so one index smaller.\n",
    "        #use e.g. structured arrays?? For now - collect all but only compare subset. Inefficient.\n",
    "        #label_model_at_x_data_current= np.zeros(x_data_to_fit.shape[0])\n",
    "        residual_at_x_data= np.zeros(x_data_to_fit.shape)\n",
    "        label_model_at_x_data= np.zeros(x_data_to_fit.shape)\n",
    "        #times_to_fit_i is relative to original time scale - need to subtract one for 'data fitting' scale (aleady discar. t0)\n",
    "        #for i in np.subtract(times_to_fit_i,1): #shift times_to_fit_i index referencing so t > t0\n",
    "        for i in range(0,len(times_to_fit_i)):\n",
    "            #TODO - assert i>0\n",
    "            #print 'i'\n",
    "            #print i\n",
    "            #label_model_at_x_data_current= np.interp(x_data_to_fit[:,i],x_centres_model[:,i],labels_model[:,i])\n",
    "            label_model_at_x_data[:,i]= np.interp(x_data_to_fit[:,i],x_centres_model[:,i],labels_model[:,i])\n",
    "            residual_at_x_data[:,i]= label_data_at_x_data[:,i]-label_model_at_x_data[:,i]\n",
    "        #print 'label model at x pre flat'\n",
    "        #print label_data_at_x_data\n",
    "        if flatten_residual:\n",
    "            if return_model:\n",
    "                return np.ravel(residual_at_x_data.T), np.ravel(label_model_at_x_data.T) #ravel flattens into single vector\n",
    "            return np.ravel(residual_at_x_data.T) #ravel flattens into single vector\n",
    "        else:\n",
    "            if return_model:\n",
    "                return residual_at_x_data, label_model_at_x_data\n",
    "            return residual_at_x_data\n",
    "        \n",
    "    #---\n",
    "    def lnlike(p_var_current):\n",
    "        \"\"\"\n",
    "        notes\n",
    "        data is available in larger function (hack for now)\n",
    "        TODO \n",
    "        - rewrite normal likelihood\n",
    "        - write binomial likelihood\n",
    "        - make sure using 'exact data' not interpolated (for both of above)\n",
    "        \"\"\"\n",
    "        #print 'likelihood'\n",
    "        #print p_var_current\n",
    "        # the log-likelihood is pretty much sum of squared residuals\n",
    "        y_bar_resid, y_bar_model= residuals(p_var_current=p_var_current,return_model=True)\n",
    "        \n",
    "        sample_size= np.ravel(sample_size_at_x_data.T)\n",
    "        y_bar_data= np.ravel(label_data_at_x_data.T)\n",
    "        sigma= np.sqrt(np.divide(y_bar_model*(1.-y_bar_model),sample_size)) #note: may include inf or nan - deal with later\n",
    "        #print 'sigma'\n",
    "        #print sigma\n",
    "        #print 'mean sigma'\n",
    "        #print np.ma.mean(sigma)\n",
    "        #print 'resid/sigma'\n",
    "        #print np.divide(resid,sigma)\n",
    "        #print 'model'\n",
    "        #print model\n",
    "        #print 'resid'\n",
    "        #print resid\n",
    "        #print 'sample size'\n",
    "        #print (np.ravel(sample_size_at_x_data.T))\n",
    "        #print np.ravel(sample_size_at_x_data.T)\n",
    "        #sigma=0.1 #temp! DOES THIS VARY?\n",
    "        #print sigma\n",
    "        #denom= np.power(sigma,2)\n",
    "        #numpy.ma.\n",
    "        #ll= -0.5*(np.sum(np.power(np.divide(resid,sigma),2))+np.sum(np.ma.log(np.power(sigma,2)*2.*np.pi)))\n",
    "        \n",
    "        #ll= -0.5*(np.power(la.norm(np.divide(y_bar_resid,sigma),2),2)+np.sum(np.ma.log(np.power(sigma,2)*2.*np.pi)))\n",
    "        ll= np.ma.sum(sample_size*(y_bar_data*np.ma.log(y_bar_model)+(1.-y_bar_data)*np.ma.log(1.-y_bar_model))) \n",
    "        #ll= BINOMIAL...\n",
    "        #print lp\n",
    "        return ll\n",
    "    \n",
    "    def lnprior(p_var_current):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # The parameters are stored as a vector of values, so unpack them?\n",
    "        #CAREFUL OF SIGMA?\n",
    "        #prior_type= 'uniform'\n",
    "        #prior_type= 'gaussian-simple'\n",
    "        prior_type= 'gaussian-with-cov'\n",
    "        if prior_type=='uniform':\n",
    "            # We're using only uniform priors (for now - try sparsity!)\n",
    "            if np.logical_or((p_var_current<-2).any(),(p_var_current>2).any()):\n",
    "                return -np.inf\n",
    "            return 0 #prior up to constant -> log up to constant\n",
    "        if prior_type=='gaussian-simple':\n",
    "            #sigma_prior= 0.1#key is ratio to sigma in likelihood??\n",
    "            sigma_prior= 2.0# typical variation in rates. Notes: 1.0 works well, 5.0 not so well - 'wiggly'\n",
    "            denom= np.power(sigma_prior,2)\n",
    "            #(la.norm(p_var-np.mean(p_var),ord=penalty_order)**penalty_order)\n",
    "            #print 'lnprior'\n",
    "            #print -0.5*(np.power(la.norm(np.divide(p_var_current-p_var0,denom),2),2)+len(p_var0)*np.log(denom*2*np.pi))\n",
    "            return -0.5*(np.power(la.norm(np.divide(p_var_current-p0[p_var_i],denom),2),2)+len(p_var_i)*np.log(denom*2*np.pi))\n",
    "            #return -0.5*(np.power(la.norm(np.divide(p_var_current-p_var0,denom),2),2)+len(p_var0)*np.log(denom*2*np.pi))\n",
    "        if prior_type=='gaussian-with-cov':\n",
    "            #use 'george' gaussian process package for now. Could do manual or could extend to proper gaussian process.\n",
    "            #-correlation matrix 2.0 usual.\n",
    "            #parameter_correlation_length= 2.0\n",
    "            parameter_correlation_length= 5.0\n",
    "            kernel = kernels.ExpSquaredKernel(0.5*parameter_correlation_length)\n",
    "            #kernel = kernels.ExpSquaredKernel(0.5) #0.5 -> correlation length approx. 1 parameter; 2*L.\n",
    "            gp = george.GP(kernel)\n",
    "            correlation_matrix= gp.get_matrix(p_var_i)\n",
    "            #-standard deviations\n",
    "            sd_decay_region=3 #number of parameters from end over which sd decays.\n",
    "            #sd_prior= 1.0*np.append(np.ones(len(p_var_i)-sd_decay_region),correlation_matrix[0,1:1+sd_decay_region]) #correlation_matrix[0,:]#\n",
    "            sd_prior= 0.5*np.append(np.ones(len(p_var_i)-sd_decay_region),correlation_matrix[0,1:1+sd_decay_region]) #correlation_matrix[0,:]#\n",
    "            #sd_prior= 1.0*np.append(np.ones(len(p_var_i)-1),0.3) #correlation_matrix[0,:]#\n",
    "            var_prior= np.outer(sd_prior,sd_prior)\n",
    "            sigma= var_prior*correlation_matrix #note: element-wise product\n",
    "            #sd=2.0\n",
    "            #sigma= sd*gp.get_matrix(p_var_i)\n",
    "            dist_dim = np.float(len(p_var_i))\n",
    "            det = np.linalg.det(sigma)\n",
    "            if det == 0:\n",
    "                raise NameError(\"The covariance matrix can't be singular\")\n",
    "            #note: calculation is in log form.\n",
    "            norm_const1 = -0.5*dist_dim*np.log(2.*np.pi)\n",
    "            norm_const2 = -0.5*np.log(det)\n",
    "            err = p_var_current-p0[p_var_i]\n",
    "            #print 'here 2'\n",
    "            #print err\n",
    "            numerator = -0.5*np.dot(err,np.dot(np.linalg.inv(sigma),err))\n",
    "            return norm_const1+norm_const2+numerator  \n",
    "    \n",
    "    def lnprob(p_var_current):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        lp = lnprior(p_var_current)\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "        return lp + lnlike(p_var_current)\n",
    "    \n",
    "    #Sampling starts\n",
    "    import emcee\n",
    "    flatten_residual= True\n",
    "    p_var0= np.copy(p0[p_var_i])\n",
    "    \n",
    "    #start walkers from where? could be p0 or maximum likelihood/optimised solution.\n",
    "    #n_walkers,n_dim = n_walkers,n_dim #50\n",
    "    #p_var0 = [p_var0+1.e-4*np.random.randn(n_dim) for i in range(n_walkers)]\n",
    "    p_var0 = [p_var0+1.e-2*np.random.randn(n_dim) for i in range(n_walkers)]\n",
    "    \n",
    "    #create sampler\n",
    "    sampler = emcee.EnsembleSampler(n_walkers,n_dim,lnprob)\n",
    "    #burn\n",
    "    import time as timer\n",
    "    t0 = timer.time()\n",
    "    pos_post_burn,prob_post_burn,state_post_burn = sampler.run_mcmc(p_var0, n_burn) #50\n",
    "    t1 = timer.time()\n",
    "    t_burn= t1-t0\n",
    "    print 'burn time: '\n",
    "    print t_burn\n",
    "    #post-burn\n",
    "    sampler.reset()\n",
    "    t0 = timer.time()\n",
    "    pos,prob,state = sampler.run_mcmc(pos_post_burn, n_sample) #1000\n",
    "    t1 = timer.time()\n",
    "    t_sampler= t1-t0\n",
    "    print 'sample time: '\n",
    "    print t_sampler\n",
    "    return sampler, t_burn, t_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a= np.array([0,1,2,3])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a= np.array([0.,1.,2.,3.])\n",
    "b= 3.*a\n",
    "print np.sum(3.*a)\n",
    "print np.sum(b)\n",
    "print np.log(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a= np.array([0.,1.,2.,3.])\n",
    "b= np.power(a,2)\n",
    "print np.log(a)\n",
    "print b\n",
    "print np.log(b)\n",
    "print np.divide(1.,2.)\n",
    "print np.divide(a,np.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num free parameters\n",
      "5\n",
      "num fixed parameters\n",
      "15\n",
      "p0: \n",
      "[ 1.   1.5  0.5  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0. ]\n",
      "here\n",
      "../data-working/TXT_AraC_01_IdU/AraC_01_1080min.txt\n",
      "AraC_01_1260min.txt\n",
      "here\n",
      "../data-working/TXT_AraC_01_IdU/AraC_01_1260min.txt\n",
      "AraC_01_1500min.txt\n",
      "here\n",
      "../data-working/TXT_AraC_01_IdU/AraC_01_1500min.txt\n",
      "2015-04-15 22:05:05,956 INFO CLAW: Solution 0 computed for time t=0.000000\n",
      "2015-04-15 22:05:05,971 INFO CLAW: Solution 1 computed for time t=0.428571\n",
      "2015-04-15 22:05:06,003 INFO CLAW: Solution 2 computed for time t=1.000000\n",
      "2015-04-15 22:05:07,042 INFO CLAW: Solution 0 computed for time t=0.000000\n",
      "2015-04-15 22:05:07,054 INFO CLAW: Solution 1 computed for time t=0.428571\n",
      "2015-04-15 22:05:07,076 INFO CLAW: Solution 2 computed for time t=1.000000\n",
      "2015-04-15 22:05:08,008 INFO CLAW: Solution 0 computed for time t=0.000000\n",
      "2015-04-15 22:05:08,021 INFO CLAW: Solution 1 computed for time t=0.428571\n",
      "2015-04-15 22:05:08,042 INFO CLAW: Solution 2 computed for time t=1.000000\n",
      "2015-04-15 22:05:09,083 INFO CLAW: Solution 0 computed for time t=0.000000\n",
      "2015-04-15 22:05:09,091 INFO CLAW: Solution 1 computed for time t=0.428571\n",
      "2015-04-15 22:05:09,112 INFO CLAW: Solution 2 computed for time t=1.000000\n",
      "2015-04-15 22:05:10,012 INFO CLAW: Solution 0 computed for time t=0.000000\n",
      "2015-04-15 22:05:10,019 INFO CLAW: Solution 1 computed for time t=0.428571\n",
      "2015-04-15 22:05:10,036 INFO CLAW: Solution 2 computed for time t=1.000000\n",
      "2015-04-15 22:05:11,189 INFO CLAW: Solution 0 computed for time t=0.000000\n",
      "2015-04-15 22:05:11,196 INFO CLAW: Solution 1 computed for time t=0.428571\n",
      "2015-04-15 22:05:11,215 INFO CLAW: Solution 2 computed for time t=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda/lib/python2.7/site-packages/scipy/integrate/quadpack.py:295: UserWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  warnings.warn(msg)\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emcee: Exception while calling your likelihood function:\n",
      "  params: [ 1.00798569  1.51070646  0.50751041  0.00739223 -0.00747245]\n",
      "  args: []\n",
      "  kwargs: {}\n",
      "  exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/user/anaconda/lib/python2.7/site-packages/emcee/ensemble.py\", line 505, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"<ipython-input-3-5dc967b258b9>\", line 257, in lnprob\n",
      "    return lp + lnlike(p_var_current)\n",
      "  File \"<ipython-input-3-5dc967b258b9>\", line 170, in lnlike\n",
      "    y_bar_resid, y_bar_model= residuals(p_var_current=p_var_current,return_model=True)\n",
      "  File \"<ipython-input-3-5dc967b258b9>\", line 125, in residuals\n",
      "    results= model(p_var_model=p_var_current)\n",
      "  File \"<ipython-input-3-5dc967b258b9>\", line 83, in model\n",
      "    controller= setup(nx=nx,initial_profile_f=initial_profile_f,velocity_f=velocity_f,norm_out_times=norm_out_times)\n",
      "  File \"<ipython-input-2-6a38c0d3d31c>\", line 63, in setup\n",
      "    state.aux[0,:]= [velocity_f(xc) for xc in x_centres]\n",
      "  File \"<ipython-input-2-ae6f1a08d928>\", line 13, in <lambda>\n",
      "    return lambda x_i: sp.integrate.quad(k_prolif,x_lower,x_i)[0]\n",
      "  File \"/Users/user/anaconda/lib/python2.7/site-packages/scipy/integrate/quadpack.py\", line 254, in quad\n",
      "    retval = _quad(func,a,b,args,full_output,epsabs,epsrel,limit,points)\n",
      "  File \"/Users/user/anaconda/lib/python2.7/site-packages/scipy/integrate/quadpack.py\", line 319, in _quad\n",
      "    return _quadpack._qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n",
      "  File \"<ipython-input-2-7978dc5d5fb4>\", line 14, in <lambda>\n",
      "    k_prolif= lambda x: p[np.floor((x/x_max)*(p.size-1.0))]\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3f35cf9c18da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m sampler, t_burn, t_sampler= sample_sim(p0=p0,p_var_i=p_var_i,n_walkers=n_walkers,n_dim=n_dim,\n\u001b[1;32m     71\u001b[0m                                        \u001b[0mn_burn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_burn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                                        actual_out_times=actual_out_times,times_to_fit_i=times_to_fit_i)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'times (burn, sampler, total): '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mt_burn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5dc967b258b9>\u001b[0m in \u001b[0;36msample_sim\u001b[0;34m(data_dir, sample_type, actual_out_times, times_to_fit_i, precision_time, p0, p_var_i, x_min, x_max, k, s, nx, n_walkers, n_dim, n_burn, n_sample)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mpos_post_burn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprob_post_burn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_post_burn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_var0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_burn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mt_burn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/anaconda/lib/python2.7/site-packages/emcee/sampler.pyc\u001b[0m in \u001b[0;36mrun_mcmc\u001b[0;34m(self, pos0, N, rstate0, lnprob0, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[1;32m    156\u001b[0m         for results in self.sample(pos0, lnprob0, rstate0, iterations=N,\n\u001b[0;32m--> 157\u001b[0;31m                                    **kwargs):\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/anaconda/lib/python2.7/site-packages/emcee/ensemble.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, p0, lnprob0, rstate0, blobs0, iterations, thin, storechain, mh_proposal)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mblobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblobs0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlnprob\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mlnprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lnprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# Check to make sure that the probability function didn't return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/anaconda/lib/python2.7/site-packages/emcee/ensemble.pyc\u001b[0m in \u001b[0;36m_get_lnprob\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;31m# Run the log-probability calculations (optionally in parallel).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlnprobfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/anaconda/lib/python2.7/site-packages/emcee/ensemble.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5dc967b258b9>\u001b[0m in \u001b[0;36mlnprob\u001b[0;34m(p_var_current)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlnlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_var_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m#Sampling starts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5dc967b258b9>\u001b[0m in \u001b[0;36mlnlike\u001b[0;34m(p_var_current)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m#print p_var_current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# the log-likelihood is pretty much sum of squared residuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0my_bar_resid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bar_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mresiduals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_var_current\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_var_current\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size_at_x_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5dc967b258b9>\u001b[0m in \u001b[0;36mresiduals\u001b[0;34m(p_var_current, flatten_residual, return_model)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m#get solutions at all fit times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_var_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_var_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mlabels_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes_to_fit_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#note: changed indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mx_centres_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes_to_fit_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#note: changed indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5dc967b258b9>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(p_var_model)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m#print 'here'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mvelocity_f\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvelocity_from_integrated_proliferation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproliferation_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mcontroller\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_profile_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_profile_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvelocity_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvelocity_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_out_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_out_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;31m#controller.verbosity= 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6a38c0d3d31c>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(nx, kernel_language, use_petsc, solver_type, weno_order, time_integrator, outdir_claw, initial_profile_f, velocity_f, norm_out_times, domain_length)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mx_centres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m \u001b[0;31m#CAREFUL OF CELL CENTRES?? TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minitial_profile_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_centres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvelocity_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_centres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m#--controller and solver--\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ae6f1a08d928>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x_i)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \"\"\"\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#could be much more efficient! can express analytically duh!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_prolif\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_lower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/user/anaconda/lib/python2.7/site-packages/scipy/integrate/quadpack.pyc\u001b[0m in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_quad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsrel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_quad_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsrel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimlst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/anaconda/lib/python2.7/site-packages/scipy/integrate/quadpack.pyc\u001b[0m in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfbounds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_quadpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qagse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsrel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_quadpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qagie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsrel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7978dc5d5fb4>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mk_prolif\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#p_grid= np.linspace(0.,1.0,p.size+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sampling approach here\n",
    "#BrdU\n",
    "#data_dir='../data-working/TXT_BrdU/'\n",
    "#sample_type='BrdU'\n",
    "#actual_out_times= np.array([120.,360.,600.])#,1920.])\n",
    "##times_to_fit_i=[1,2]\n",
    "#times_to_fit_i=[1,2]\n",
    "\n",
    "#AraC\n",
    "data_dir='../data-working/TXT_AraC_01_IdU/'\n",
    "sample_type='AraC'\n",
    "#actual_out_times= np.array([1080,1260.,1500.])\n",
    "#actual_out_times= np.array([1260.,1500.])#,1620.])\n",
    "#actual_out_times= np.array([1140.,1260.])#,1620.])\n",
    "#actual_out_times= np.array([1140.,1500.])#,1620.])\n",
    "#actual_out_times= np.array([1620.,2520.])#,1620.])\n",
    "actual_out_times= np.array([2100.,2520.])#,1620.])\n",
    "#times_to_fit_i=[1,2]\n",
    "times_to_fit_i=[1]\n",
    "#times_to_fit_i=[2]\n",
    "\n",
    "#GLP2_01\n",
    "#Low\n",
    "#data_dir='../data-working/TXT_GLP2_01_Ileums/Low/'\n",
    "#sample_type='GLP2_01_Ileums_Low'\n",
    "#actual_times= np.array([1500,2400.])\n",
    "#Med\n",
    "#data_dir='../data-working/TXT_GLP2_01_Ileums/Med_Full/'\n",
    "#sample_type='GLP2_01_Ileums_Med'\n",
    "#actual_out_times= np.array([60.,1020.,1620.])#,2460.])\n",
    "#High\n",
    "#data_dir='../data-working/TXT_GLP2_01_Ileums/High_Full/'\n",
    "#sample_type='GLP2_01_Ileums_High'\n",
    "#actual_out_times= np.array([60.,1020.,2460.])\n",
    "#times_to_fit_i= [1,2]\n",
    "\n",
    "#p0=np.random.uniform(low=-1.0,high=1.0,size=3)\n",
    "#p0= np.append(p0,np.zeros(17))\n",
    "#p0= np.array([0.5,0.5,0.5,0.5])\n",
    "#p0= np.array([0.0,0.0,0.0,0.0])\n",
    "p0= np.array([0.5,1.5,0.5,0.0,0.0])#decent guess at solution, based on opt.\n",
    "#p0= np.array([0.1,0.1,0.1,0.0,0.0])#decent guess at solution, based on opt.\n",
    "p_var_i= [0,1,2,3,4]\n",
    "p0= np.append(p0,np.zeros(15))\n",
    "\n",
    "print 'num free parameters'\n",
    "print len(p_var_i)\n",
    "print 'num fixed parameters'\n",
    "print len(p0)-len(p_var_i)\n",
    "\n",
    "#p0[p_var_i]= [0.50270828, 1.58121376, 0.17217782, -0.0203373] #from optimisation run!\n",
    "\n",
    "p_start= np.copy(p0)\n",
    "print 'p0: ' \n",
    "print p0\n",
    "\n",
    "n_dim=len(p_var_i)\n",
    "#minimal test #(10,2,2 = about 30-40 sec? For 4 parameters.)\n",
    "#n_walkers= 10\n",
    "#n_burn=2\n",
    "#n_sample=2\n",
    "#medium test (20, 100, 100 = about one hour? For 4 parameters)\n",
    "#n_walkers= 20\n",
    "#n_burn=100\n",
    "#n_sample=100\n",
    "#--TO USE--\n",
    "#(100, 100, 100 = about 5 hours for 4 parameters)\n",
    "#n_walkers= 100 \n",
    "#n_burn=100\n",
    "#n_sample=100\n",
    "#(50, 100, 100 = about 2.5 hours for 4 parameters?) More like 2.7 these days? Similar for 5 param.\n",
    "n_walkers= 50 \n",
    "n_burn=100\n",
    "n_sample=100\n",
    "\n",
    "sampler, t_burn, t_sampler= sample_sim(p0=p0,p_var_i=p_var_i,n_walkers=n_walkers,n_dim=n_dim,\n",
    "                                       n_burn=n_burn,n_sample=n_sample,data_dir=data_dir,sample_type=sample_type,\n",
    "                                       actual_out_times=actual_out_times,times_to_fit_i=times_to_fit_i)\n",
    "print 'times (burn, sampler, total): '\n",
    "print t_burn\n",
    "print t_sampler\n",
    "t_total= t_burn+t_sampler\n",
    "print t_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-51f796322983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtriangle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtri_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_var_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_var_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#tmp.savefig()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                      truths=[alpha_true, beta_x_true, beta_y_true, eps_true])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampler' is not defined"
     ]
    }
   ],
   "source": [
    "import triangle\n",
    "tri_plot = triangle.corner(sampler.flatchain, labels=['p'+str(p_var_i[i]) for i in range(0,len(p_var_i))])\n",
    "#tmp.savefig()\n",
    "#                      truths=[alpha_true, beta_x_true, beta_y_true, eps_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save triangle plot\n",
    "\n",
    "#sample_type= 'BrdU'\n",
    "output_path= '../figures/proliferation_profiles/'\n",
    "save_path= output_path+sample_type+'/'\n",
    "save_fig= True\n",
    "if save_fig:\n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(save_path):\n",
    "            pass\n",
    "        else: raise\n",
    "    tri_plot.savefig(save_path+'mcmc-proliferation-rates-'+sample_type+'.pdf')\n",
    "tri_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save sampler outputs\n",
    "import pickle\n",
    "\n",
    "#sample_type= 'BrdU'\n",
    "output_path= '../raw-output/'\n",
    "save_path= output_path+sample_type+'/'\n",
    "save_raw= True\n",
    "if save_raw:\n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(save_path):\n",
    "            pass\n",
    "        else: raise\n",
    "    pickle.dump( sampler.chain, open( save_path+\"sampler_chain_\"+sample_type+\".p\", \"wb\" ) )\n",
    "    pickle.dump( sampler.flatchain, open( save_path+\"sampler_flat_chain_\"+sample_type+\".p\", \"wb\" ) )\n",
    "    pickle.dump( sampler.acceptance_fraction, open( save_path+\"sampler_acceptance_fraction_\"+sample_type+\".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./np.divide(1.,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "[[0 1 4 3]\n",
      " [0 1 2 3]]\n",
      "[0 2 3]\n",
      "[[0 1 4]\n",
      " [0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "a= [0,1,2]\n",
    "b= np.array([0,2,3,4])\n",
    "c= np.array([[0,1,4,3],[0,1,2,3]])\n",
    "print len(a)\n",
    "print len(b)\n",
    "print c\n",
    "print b[a]\n",
    "print c[:,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(a)):\n",
    "    print i\n",
    "print len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'infmean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-199f12ec27e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'infmean'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
